{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import polars as pl\n",
    "\n",
    "from transformers import LlamaModel, LlamaTokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_dataset_path = '../data/Beauty/Beauty_5.json'\n",
    "metadata_path = '../data/Beauty/metadata.json'\n",
    "\n",
    "interactions_output_path = '../data/Beauty/inter.json'\n",
    "embeddings_output_path = '../data/Beauty/content_embeddings.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(list)\n",
    "\n",
    "with open(interactions_dataset_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        review = json.loads(line)\n",
    "        df['user_id'].append(review['reviewerID'])\n",
    "        df['item_id'].append(review['asin'])\n",
    "        df['timestamp'].append(review['unixReviewTime'])\n",
    "\n",
    "print(f'Number of events: {len(df[\"user_id\"])}')\n",
    "\n",
    "df = pl.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26746c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bbf9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing dataset to get core-5 state in case full dataset is provided\n",
    "is_changed = True\n",
    "threshold = 5\n",
    "good_users = set()\n",
    "good_items = set()\n",
    "\n",
    "while is_changed:\n",
    "    user_counts = filtered_df.group_by('user_id').agg(\n",
    "        pl.len().alias('user_count'),\n",
    "    )\n",
    "    item_counts = filtered_df.group_by('item_id').agg(\n",
    "        pl.len().alias('item_count'),\n",
    "    )\n",
    "\n",
    "    good_users = user_counts.filter(pl.col('user_count') >= threshold).select(\n",
    "        'user_id',\n",
    "    )\n",
    "    good_items = item_counts.filter(pl.col('item_count') >= threshold).select(\n",
    "        'item_id',\n",
    "    )\n",
    "\n",
    "    old_size = len(filtered_df)\n",
    "\n",
    "    new_df = filtered_df.join(good_users, on='user_id', how='inner')\n",
    "    new_df = new_df.join(good_items, on='item_id', how='inner')\n",
    "\n",
    "    new_size = len(new_df)\n",
    "\n",
    "    filtered_df = new_df\n",
    "    is_changed = old_size != new_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = filtered_df[\"user_id\"].unique(maintain_order=True).to_list()\n",
    "user_ids_mapping = {value: i for i, value in enumerate(unique_values)}\n",
    "\n",
    "filtered_df = filtered_df.with_columns(\n",
    "    pl.col(\"user_id\").replace_strict(user_ids_mapping)\n",
    ")\n",
    "\n",
    "unique_values = filtered_df[\"item_id\"].unique(maintain_order=True).to_list()\n",
    "item_ids_mapping = {value: i for i, value in enumerate(unique_values)}\n",
    "\n",
    "filtered_df = filtered_df.with_columns(\n",
    "    pl.col(\"item_id\").replace_strict(item_ids_mapping)\n",
    ")\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34604fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids_mapping_df = pl.from_dict({\n",
    "    'old_item_id': list(item_ids_mapping.keys()),\n",
    "    'new_item_id': list(item_ids_mapping.values())\n",
    "})\n",
    "item_ids_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.sort([\"user_id\", \"timestamp\"])\n",
    "\n",
    "grouped_filtered_df = filtered_df.group_by(\"user_id\", maintain_order=True).agg(pl.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0821da",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc222d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Users count:', filtered_df.select('user_id').unique().shape[0])\n",
    "print('Items count:', filtered_df.select('item_id').unique().shape[0])\n",
    "print('Actions count:', filtered_df.shape[0])\n",
    "print('Avg user history len:', np.mean(list(map(lambda x: x[0], grouped_filtered_df.select(pl.col('item_id').list.len()).rows()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {}\n",
    "for user_id, item_ids, _ in grouped_filtered_df.iter_rows():\n",
    "    json_data[user_id] = item_ids\n",
    "\n",
    "with open(interactions_output_path, 'w') as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237523fa",
   "metadata": {},
   "source": [
    "## Content embedding creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            df[i] = eval(line)\n",
    "            i += 1\n",
    "\n",
    "    return pd.DataFrame.from_dict(df, orient=\"index\")\n",
    "\n",
    "df = getDF(metadata_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971fa89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row: pd.Series):\n",
    "    row = row.fillna(\"None\")\n",
    "    return f\"Title: {row['title']}. Categories: {', '.join(row['categories'][0])}. Description: {row['description']}.\"\n",
    "\n",
    "\n",
    "def get_data(metadata_df, item_ids_mapping_df):\n",
    "    filtered_df = metadata_df.join(\n",
    "        item_ids_mapping_df, \n",
    "        left_on=\"asin\", \n",
    "        right_on='old_item_id', \n",
    "        how=\"inner\"\n",
    "    ).select(pl.col('new_item_id'), pl.col('title'), pl.col('description'), pl.col('categories'))\n",
    "\n",
    "    filtered_df = filtered_df.to_pandas()\n",
    "    filtered_df[\"combined_text\"] = filtered_df.apply(preprocess, axis=1)\n",
    "\n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dd5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(pl.from_pandas(df), item_ids_mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e622ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:6')\n",
    "\n",
    "model_name = \"huggyllama/llama-7b\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = LlamaModel.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "class MyDataset:\n",
    "    def __init__(self, data):\n",
    "        self._data = list(zip(data.to_dict()['new_item_id'].values(), data.to_dict()['combined_text'].values()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self._data[idx][1]\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "        return {\n",
    "            'item_id': self._data[idx][0],\n",
    "            'input_ids': inputs['input_ids'][0],\n",
    "            'attention_mask': inputs['attention_mask'][0]\n",
    "        }\n",
    "    \n",
    "\n",
    "dataset = MyDataset(data)\n",
    "loader = DataLoader(dataset, batch_size=8, drop_last=False, shuffle=False, num_workers=10)\n",
    "\n",
    "\n",
    "new_df = {\n",
    "    'item_id': [],\n",
    "    'embedding': []\n",
    "}\n",
    "\n",
    "for batch in tqdm(loader):\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"].to(device), \n",
    "            attention_mask=batch[\"attention_mask\"].to(device)\n",
    "        )\n",
    "        embeddings = outputs.last_hidden_state\n",
    "    \n",
    "        embeddings = outputs.last_hidden_state  # (bs, sl, ed)\n",
    "        embeddings[(~batch[\"attention_mask\"].bool())] = 0. # (bs, sl, ed)\n",
    "\n",
    "    new_df['item_id'] += batch['item_id'].tolist()\n",
    "    new_df['embedding'] += embeddings.mean(dim=1).tolist()  # (bs, ed)\n",
    "\n",
    "\n",
    "with open(embeddings_output_path, 'wb') as f:\n",
    "    pickle.dump(new_df, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
